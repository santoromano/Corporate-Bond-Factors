{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82dd4293-2914-4de8-b48c-7b7f8a45b42c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cleans TRACE Corporate Bond Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e02e1d8-eb0d-4cc3-8f09-42b521a26d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca3961e-13eb-4b12-b2ef-11b017c9a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in subset of prof Yoshio's data\n",
    "with pd.read_csv(\"prof_yoshio_data/trace_credit_spreads.csv\", chunksize=1000) as reader:\n",
    "    data = reader.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e249196-425e-4c10-95a1-11b68ac0f94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 40 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   cusip_id                1000 non-null   object \n",
      " 1   date                    1000 non-null   int64  \n",
      " 2   price                   1000 non-null   float64\n",
      " 3   volume                  1000 non-null   int64  \n",
      " 4   ISSUE_ID                1000 non-null   int64  \n",
      " 5   ISSUER_ID               1000 non-null   int64  \n",
      " 6   PROSPECTUS_ISSUER_NAME  1000 non-null   object \n",
      " 7   MATURITY                1000 non-null   int64  \n",
      " 8   SECURITY_LEVEL          1000 non-null   object \n",
      " 9   OFFERING_AMT            1000 non-null   int64  \n",
      " 10  OFFERING_DATE           1000 non-null   int64  \n",
      " 11  OFFERING_PRICE          852 non-null    float64\n",
      " 12  INTEREST_FREQUENCY      1000 non-null   int64  \n",
      " 13  COUPON                  1000 non-null   float64\n",
      " 14  standard                1000 non-null   int64  \n",
      " 15  putop                   1000 non-null   int64  \n",
      " 16  conv                    1000 non-null   int64  \n",
      " 17  junior                  1000 non-null   int64  \n",
      " 18  cusip                   1000 non-null   object \n",
      " 19  CALLABLE                842 non-null    object \n",
      " 20  MAKE_WHOLE              842 non-null    object \n",
      " 21  INDUSTRY_CODE           1000 non-null   int64  \n",
      " 22  SIC_CODE                1000 non-null   int64  \n",
      " 23  rating_date_spr         1000 non-null   int64  \n",
      " 24  rating_spr              1000 non-null   object \n",
      " 25  rating_mdy              987 non-null    object \n",
      " 26  rating_date_mdy         0 non-null      float64\n",
      " 27  SP_rat                  995 non-null    float64\n",
      " 28  Moody_rat               987 non-null    float64\n",
      " 29  AMOUNT_OUTSTANDING      1000 non-null   int64  \n",
      " 30  month1                  1000 non-null   int64  \n",
      " 31  accrued_interest        1000 non-null   float64\n",
      " 32  tau                     1000 non-null   float64\n",
      " 33  age                     1000 non-null   float64\n",
      " 34  rating                  1000 non-null   int64  \n",
      " 35  ytm                     927 non-null    float64\n",
      " 36  duration                927 non-null    float64\n",
      " 37  tr_dirty_price          927 non-null    float64\n",
      " 38  tr_ytm                  927 non-null    float64\n",
      " 39  cs                      927 non-null    float64\n",
      "dtypes: float64(14), int64(18), object(8)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5c0dd8ca-bb12-4d86-8518-beb92f3bd321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.memory_usage(deep=True) \\\n",
    "# .gt(8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f148fcd3-e317-47d7-8d08-1d30e58e0403",
   "metadata": {},
   "source": [
    "As expected all \"object\" (ie. string) columns use up the majority of the memory. The rest (float/int64s) are using 8 bytes, however these may also be reduced to 16 or 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "ab1a0cc5-0a52-46ce-ac7b-152a0ec0c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols(col_names, data_type):\n",
    "    '''\n",
    "    Takes in list of column names and a datatype and generates a dictionary\n",
    "    '''\n",
    "    return {col_names[i]: data_type for i in range(len(col_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "3af87430-99f6-4ef5-b3bb-29f361a51f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_types(df):\n",
    "    '''\n",
    "    Cleans datatypes for raw data\n",
    "    '''\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    \n",
    "    # String/text columns\n",
    "    string_cols = ['cusip_id', 'cusip', 'prospectus_issuer_name']\n",
    "    strings = cols(string_cols, 'string[pyarrow]')\n",
    "\n",
    "    bool_cols = ['callable', 'make_whole', 'conv', 'junior']\n",
    "    bools = cols(bool_cols, 'bool')\n",
    "\n",
    "    category_cols = ['security_level', 'rating_spr', 'rating_mdy', 'standard', 'putop', 'industry_code']\n",
    "    categories = cols(category_cols, 'category')\n",
    "    try:\n",
    "        df = df.drop([\"sp_rat\", \"moody_rat\", \"rating\", 'rating_date_spr', 'rating_date_mdy'], axis=1)\n",
    "    except: pass\n",
    "        \n",
    "    # Float/Integer columns\n",
    "    int8_cols = ['interest_frequency']\n",
    "    int8s = cols(int8_cols, 'int8')\n",
    "\n",
    "    df['sic_code'] = df['sic_code'].fillna(0)\n",
    "    int16_cols = ['sic_code']\n",
    "    int16s = cols(int16_cols, 'int16')\n",
    "\n",
    "    int32_cols = ['volume', 'offering_amt', 'amount_outstanding', 'issue_id', 'issuer_id']\n",
    "    int32s = cols(int32_cols, 'int32')\n",
    "\n",
    "    float32_cols = ['price', 'offering_price', 'coupon', 'accrued_interest', 'tau',\n",
    "                   'age', 'ytm', 'duration', 'tr_dirty_price', 'tr_ytm', 'cs']\n",
    "    float32s = cols(float32_cols, 'float32')\n",
    "\n",
    "    # Dates\n",
    "    # formula to convert to datetime: df['date'].apply(lambda x: pd.to_datetime(str(x), format='%Y%m%d'))\n",
    "    df['offering_date'] = df['offering_date'].fillna(0)\n",
    "    date_cols = ['date', 'maturity', 'offering_date', 'month1']\n",
    "    dates = cols(date_cols, 'int32')\n",
    "\n",
    "    # Applies type changes\n",
    "    types = strings | bools | categories | int8s | int16s | int32s | float32s | dates\n",
    "\n",
    "    return df.astype(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "675aabaa-cb11-41e6-b986-4c3c2b20d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data_types(df)\n",
    "# df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2ac7f211-0018-4d1f-a7ac-0d50c0f0b530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 35 columns):\n",
      " #   Column                  Non-Null Count  Dtype   \n",
      "---  ------                  --------------  -----   \n",
      " 0   cusip_id                1000 non-null   string  \n",
      " 1   date                    1000 non-null   int32   \n",
      " 2   price                   1000 non-null   float32 \n",
      " 3   volume                  1000 non-null   int32   \n",
      " 4   issue_id                1000 non-null   int32   \n",
      " 5   issuer_id               1000 non-null   int32   \n",
      " 6   prospectus_issuer_name  1000 non-null   string  \n",
      " 7   maturity                1000 non-null   int32   \n",
      " 8   security_level          1000 non-null   category\n",
      " 9   offering_amt            1000 non-null   int32   \n",
      " 10  offering_date           1000 non-null   int32   \n",
      " 11  offering_price          852 non-null    float32 \n",
      " 12  interest_frequency      1000 non-null   int8    \n",
      " 13  coupon                  1000 non-null   float32 \n",
      " 14  standard                1000 non-null   category\n",
      " 15  putop                   1000 non-null   category\n",
      " 16  conv                    1000 non-null   bool    \n",
      " 17  junior                  1000 non-null   bool    \n",
      " 18  cusip                   1000 non-null   string  \n",
      " 19  callable                1000 non-null   bool    \n",
      " 20  make_whole              1000 non-null   bool    \n",
      " 21  industry_code           1000 non-null   category\n",
      " 22  sic_code                1000 non-null   int16   \n",
      " 23  rating_spr              1000 non-null   category\n",
      " 24  rating_mdy              987 non-null    category\n",
      " 25  amount_outstanding      1000 non-null   int32   \n",
      " 26  month1                  1000 non-null   int32   \n",
      " 27  accrued_interest        1000 non-null   float32 \n",
      " 28  tau                     1000 non-null   float32 \n",
      " 29  age                     1000 non-null   float32 \n",
      " 30  ytm                     927 non-null    float32 \n",
      " 31  duration                927 non-null    float32 \n",
      " 32  tr_dirty_price          927 non-null    float32 \n",
      " 33  tr_ytm                  927 non-null    float32 \n",
      " 34  cs                      927 non-null    float32 \n",
      "dtypes: bool(4), category(6), float32(11), int16(1), int32(9), int8(1), string(3)\n",
      "memory usage: 135.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# Memory usage decreased by about half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ec4e4691-ee9d-447b-9d7c-03348cdb06c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sroma\\AppData\\Local\\Temp\\ipykernel_25248\\3165405631.py:2: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"prof_yoshio_data/trace_credit_spreads.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14090424.827 KB\n"
     ]
    }
   ],
   "source": [
    "# Loads in whole data\n",
    "data = pd.read_csv(\"prof_yoshio_data/trace_credit_spreads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4bec9e4d-0e9f-4021-ae4e-99899d159ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14090424.827 KB\n"
     ]
    }
   ],
   "source": [
    "# Cleans data\n",
    "cleaned_data = clean_data_types(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c22446-dd6b-4832-92e0-cafd1be6b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves cleaned data\n",
    "cleaned_data.to_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "65514762-b45d-490c-b55f-d09c9346c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "b8c8a2f3-d058-48c3-8ce9-62ecbdd20320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6956fea-eaea-40fd-86b1-25e583b002f8",
   "metadata": {},
   "source": [
    "# Aggregates Data to Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "13fe0ecf-a975-4340-a08e-b726f01eb58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.relativedelta import *\n",
    "from pandas.tseries.offsets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "6ccd3534-c240-40a9-94c2-23cabbd88608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in subset of cleaned data\n",
    "with pd.read_csv(\"cleaned_data.csv\", chunksize=100_000, index_col=0) as reader:\n",
    "    data = reader.get_chunk()\n",
    "\n",
    "# csv doesn't preserve data types\n",
    "data = clean_data_types(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1aa581de-32db-4929-8735-c51c0b14654d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " With the subset of data there are: \n",
      "    - 43 unique issuers \n",
      "    - 192 unique bonds  \n",
      "    - 4913 days in the sample\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f''' With the subset of data there are: \n",
    "    - {len(data['issuer_id'].unique())} unique issuers \n",
    "    - {len(data['issue_id'].unique())} unique bonds  \n",
    "    - {len(data['date'].sort_values().unique())} days in the sample\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38be9865-b536-4770-8f5c-abafb110ae26",
   "metadata": {},
   "source": [
    "## Sample Exclusion Criteria\n",
    "Based on Bai, Bali & Wen (2019):\n",
    "\n",
    "1. Remove bonds that are not listed or traded in the US public market, which include bonds issued through private placement, bonds issued under the 144A rule, bonds that do not trade in US dollars, and bond issuers not in the jurisdiction of the United States.\n",
    "2. Remove bonds that are structured notes, mortgage backed or asset backed, agency backed, or equity linked.\n",
    "3. Remove convertible bonds since this option feature distorts the return calculation and makes it impossible to compare the returns of convertible and nonconvertible bonds.\n",
    "4. Remove bonds that trade under 5 or above 1000. \n",
    "5. Remove bonds that have a floating coupon rate, which means the sample comprises only bonds with a fixed or zero coupon. This rule is applied based on the consideration of the accuracy in bond return calculation, given the challenge in tracking a floating-coupon bond’s cash flows.\n",
    "6. Remove bonds that have less than one year to maturity. This rule is applied to all major corporate bond indices such as the Barclays Capital Corporate Bond Index, the Bank of America Merrill Lynch Corporate Master Index, and the Citi Fixed Income Indices. If a bond has less than one year to maturity, it will be delisted from major bond indices; hence, index-tracking investors will change their holding positions. This operation will distort the return calculation for bonds with less than one year to maturity; thus, we remove them from our sample.\n",
    "7. For intraday data, we also eliminate bond transactions that are labeled as when-issued, locked-in, or have special sales conditions, and that have more than a twoday settlement.\n",
    "8. Remove transaction records that are canceled and adjust records that are subsequently corrected or reversed.\n",
    "9. Remove transaction records that have trading volume less than $10,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03932e4e-07f1-4142-8955-cd91cc9818f3",
   "metadata": {},
   "source": [
    "### 3. Convertible Bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5ba33f42-6154-4111-a767-8d4daaab0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bond_convertible(data):\n",
    "    '''\n",
    "    Function which filters out convertible bonds.\n",
    "    '''\n",
    "    \n",
    "    return data[data['conv'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6ec38a7f-8bd0-42dd-acb5-afafb48339aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filter_bond_convertible(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d59112-8437-4ea2-91ca-d55ff326017d",
   "metadata": {},
   "source": [
    "### 4. Bonds with irregular trading prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2324e681-f03a-4c21-9097-e7b08cad9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bond_prices(data):\n",
    "    '''\n",
    "    Function which filters out bonds that trade below $5 or above $1000.\n",
    "    '''\n",
    "    \n",
    "    return data[(data['price'].gt(5)) | (data['price'].lt(1000))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c899a17-dca3-48bc-adbe-2f22b2bec2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filter_bond_prices(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497bb38-2592-484d-89e0-f0947c36d6b7",
   "metadata": {},
   "source": [
    "### 6. Bonds with less than 1-year to maturity\n",
    "Perhaps worthwhile to keep seperate as a robustness check?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4bb2d84d-ab5a-468f-8bd3-7cb145b15106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bond_maturity(data):\n",
    "    '''\n",
    "    Function which filters out bonds with less than 1-year to maturity.\n",
    "    Saves bonds with less than 1-year to maturity in a seperate file.\n",
    "    '''\n",
    "    data['date'] = pd.to_datetime(data['date'], format='%Y%m%d')\n",
    "    data['maturity'] = pd.to_datetime(data['maturity'], format='%Y%m%d')\n",
    "\n",
    "    data = data.sort_values(by='date')\n",
    "    data['days_to_maturity'] = data['maturity'] - data['date']\n",
    "\n",
    "    # Filters out bonds with less than 1-year to maturity\n",
    "    data_one_year_bonds = data[data['days_to_maturity'].le('365 days')]\n",
    "    data_one_year_bonds.to_csv('bonds_1_year_maturity.csv')\n",
    "    \n",
    "    return data[data['days_to_maturity'].gt('365 days')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "da3f7cd4-8c2f-49b1-b88b-72d4986f5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filter_bond_maturity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf07f577-c07d-47a6-8acb-7ce27580e8c0",
   "metadata": {},
   "source": [
    "### 9. Bonds with small trading volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ee7b6b17-de85-4d54-add6-60f571c58665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bond_volume(data):\n",
    "    '''\n",
    "    Function which filters daily volumes of less than $10,000.\n",
    "    '''\n",
    "    \n",
    "    return data[data['volume'].gt(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b8154393-ca29-4694-9cf9-161fe67d0dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filter_bond_volume(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9361e-68e8-45fe-9b7c-fb276d02c450",
   "metadata": {},
   "source": [
    "## Monthly Return Aggregation\n",
    "\n",
    "The monthly corporate bond return at time $t$ is computed as \n",
    "\n",
    "<font size=5>\n",
    "$\n",
    "r_{i,t} = \\frac{P_{i,t} + AI_{i,t} + C_{i,t}}{P_{i,t−1} + AI_{i,t−1}} − 1\n",
    "$\n",
    "</font>\n",
    "\n",
    "Where $P_{i,t}$ is month $t$'s bond clean price, $AI_{i,t}$ is the accrued-interest, and $C_{i,t}$ is the coupon.\n",
    "\n",
    "Excess returns are computed by deducting the 1-month Treasury bill rate.\n",
    "\n",
    "Further, following Bai, Bali & Wen (2019), returns can be computed as either end of month t relative to end of month t-1, or end of month t to begining of month t. Where the end/beginning of the month is defined with a 5 day window. The date which is closest to the last/firsy trading day is used. If both such return calculations are available, then the end-to-end is prefered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950e159f-9537-405e-8a67-df8c3afbe3b6",
   "metadata": {},
   "source": [
    "#### End-to-End Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "168adaf3-f8ab-4149-86ee-9585ad91138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_month_returns(data):\n",
    "    '''\n",
    "    Function to compute monthly returns using the end-to-end method.\n",
    "    '''\n",
    "    # Ensures that data is sorted in chronological order\n",
    "    data = data.sort_values(by='date')\n",
    "    \n",
    "    # Gets 5 days from the end of the month\n",
    "    data['month_end'] = data['date'] + MonthEnd(0) - pd.Timedelta(days=5)\n",
    "    \n",
    "    # Groups by issue id and year-month: returns the last observation\n",
    "    data = data.groupby(['issue_id', data['date'].dt.year, data['date'].dt.month]).tail(1).copy()\n",
    "    \n",
    "    # Creates the P + AI + C for time t\n",
    "    data['full_price_t'] = data['price'] + data['accrued_interest'] + data['coupon']\n",
    "    data['price_t'] = data['price'] + data['accrued_interest']\n",
    "    \n",
    "    # Lags P + AI\n",
    "    data['price_t1'] = data.groupby('issue_id')['price_t'].shift(1)\n",
    "    \n",
    "    # Computes the return only if the transaction date is within 5 days of end of month\n",
    "    data['return'] = np.where(~(data['date'] < data['month_end']), \n",
    "                               (data['full_price_t'] / data['price_t1']) - 1, np.nan)\n",
    "    \n",
    "    # Price return used for validation\n",
    "    data['price_return'] = np.where(~(data['date'] < data['month_end']), \n",
    "                               (data['price'] / data.groupby('issue_id')['price'].shift(1)) - 1, np.nan)\n",
    "    \n",
    "    # Drops observations where there is no return, assigns month end value\n",
    "    data = data.dropna(subset='return')\n",
    "    data['date'] = data['date'] + MonthEnd(0)\n",
    "\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "60738258-d1bb-49ab-be5b-10259f9d0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_data = end_month_returns(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157190fd-287b-4b98-b2c0-d2955e34f506",
   "metadata": {},
   "source": [
    "#### Start-to-End Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "808f6517-2ab5-475b-80c5-96b32bc4d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_month_returns(data):\n",
    "    '''\n",
    "    Function to compute monthly returns using the start-to-end method.\n",
    "    '''\n",
    "    # Ensures that data is sorted in chronological order\n",
    "    data = data.sort_values(by='date')\n",
    "    \n",
    "    # 5 days from start and end of month\n",
    "    data['month_end'] = data['date'] + MonthEnd(0) - pd.Timedelta(days=5)\n",
    "    data['month_start'] = data['date'] + MonthEnd(0) - MonthBegin(1) + pd.Timedelta(days=5)\n",
    "    data['date_t'] = data['date'] + MonthEnd(0)\n",
    "    \n",
    "    # Seperate first and last trade dataframes\n",
    "    first = data.groupby(['issue_id', data['date'].dt.year, data['date'].dt.month]).head(1).copy()\n",
    "    last = data.groupby(['issue_id', data['date'].dt.year, data['date'].dt.month]).tail(1).copy()\n",
    "    \n",
    "    # Respective price only if date requirement is satisifed \n",
    "    first['price_t'] = np.where((first['date'] < first['month_start']),\n",
    "                                 first['price'] + first['accrued_interest'], np.nan)\n",
    "    last['full_price_t'] = np.where(~(last['date'] < last['month_end']),\n",
    "                                      last['price'] + last['accrued_interest'] + last['coupon'], np.nan)\n",
    "    \n",
    "    # Merges first and last on true month end\n",
    "    merged = pd.merge(first, last[['issue_id', 'date_t', 'full_price_t']], on=['issue_id', 'date_t'])\n",
    "\n",
    "    # Computes the return\n",
    "    merged['return'] = (merged['full_price_t'] / merged['price_t']) - 1\n",
    "    \n",
    "    # Drops observations where there is no return, assigns month end value\n",
    "    data = merged.dropna(subset='return').copy()\n",
    "    data['date'] = data['date'] + MonthEnd(0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "2b84da7b-7a6d-4413-8014-bb80f3c6d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_data = start_month_returns(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2dafa3-f226-4327-a649-c88c50c26de7",
   "metadata": {},
   "source": [
    "#### Merging of Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "1ad9c53e-fcd9-4f5b-b9e3-ccbe033c7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_start_end(start_data, end_data):\n",
    "    '''\n",
    "    Function to merge start and end method return calculations.\n",
    "    Preference for end method.\n",
    "    '''\n",
    "    cols = ['date', 'issue_id', 'cusip_id', 'volume', 'issuer_id',\n",
    "       'prospectus_issuer_name', 'maturity', 'offering_amt',\n",
    "       'interest_frequency', 'cusip', 'industry_code', 'sic_code', 'rating_spr', 'rating_mdy',\n",
    "       'amount_outstanding', 'tau', 'age', 'ytm',\n",
    "       'duration', 'tr_dirty_price', 'tr_ytm', 'return']\n",
    "\n",
    "    # Subsets data and outer merges\n",
    "    end_data = end_data[cols]\n",
    "    start_data = start_data[cols]\n",
    "\n",
    "    merged = pd.merge(end_data, start_data, on=['issue_id', 'date'], how='outer', suffixes=('','_start'))\n",
    "\n",
    "    # Takes data from end method, if not available takes from start method\n",
    "    for col in cols[2:]:\n",
    "        merged[col] = np.where(merged[col].isna(), merged[col+'_start'], merged[col])\n",
    "    \n",
    "    merged = merged[cols]\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "619f2a17-acdb-421f-84d2-d13782b0db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = merge_start_end(start_data, end_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b2ff8-c627-48ad-bcac-62cfd9477d6d",
   "metadata": {},
   "source": [
    "## Complete Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "389d900f-b439-46c9-883a-7623da4b7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_to_monthly(data):\n",
    "    '''\n",
    "    Function to perform all sample exclusion, and monthly aggregation functions \n",
    "    '''\n",
    "    \n",
    "    # Filtering functions\n",
    "    data = (data.pipe(filter_bond_convertible)\n",
    "            .pipe(filter_bond_prices)\n",
    "            .pipe(filter_bond_maturity)\n",
    "            .pipe(filter_bond_volume)\n",
    "        )\n",
    "    \n",
    "    # Return calculation\n",
    "    end_data = end_month_returns(data)\n",
    "    start_data = start_month_returns(data)\n",
    "    \n",
    "    # Final merge\n",
    "    data_merged = merge_start_end(start_data, end_data)\n",
    "    \n",
    "    return data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "3a61d25d-e3f0-4f71-9b3a-478d547898c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in data\n",
    "data = pd.read_csv(\"cleaned_data.csv\", index_col=0)\n",
    "data = clean_data_types(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "f4f44431-d416-4bc8-9cae-7c74b318dd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2107,)"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data['issue_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "b602658a-2286-47d6-a035-1915e16b56e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs monthly aggregation\n",
    "monthly_data = agg_to_monthly(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "83fa75e5-d3a4-458f-86c6-635325f69906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1895,)"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# monthly_data['issue_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "2a535322-44f5-4a3a-89b3-ad4a7d37e3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87369, 22)"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "db0c5dc0-6b28-40b0-b2f4-4c8d71c47ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_data.to_csv('monthly_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaffdf8-6d67-4f84-bbc5-178cb1bf0079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
